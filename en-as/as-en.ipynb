{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11811536,"sourceType":"datasetVersion","datasetId":7418426},{"sourceId":12091997,"sourceType":"datasetVersion","datasetId":7612090},{"sourceId":12092002,"sourceType":"datasetVersion","datasetId":7612094}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:16:07.007613Z","iopub.execute_input":"2025-06-09T19:16:07.007869Z","iopub.status.idle":"2025-06-09T19:16:07.607533Z","shell.execute_reply.started":"2025-06-09T19:16:07.007845Z","shell.execute_reply":"2025-06-09T19:16:07.606756Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/emnlp-dataset-2025/English-Mizo Traning Data 2025.xlsx\n/kaggle/input/emnlp-dataset-2025/English-Nyishi Training Data 2025.xlsx\n/kaggle/input/emnlp-dataset-2025/English-Assamese Training Data 2025.csv\n/kaggle/input/emnlp-dataset-2025/English-Manipuri Training Data 2025.xlsx\n/kaggle/input/emnlp-dataset-2025/English-Khasi Training Data 2025.xlsx\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Mizo/en-lus.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Mizo/lus-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Assamese/as-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Assamese/en-as.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Manipuri/en-mni.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Manipuri/mni-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Khasi/kha-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Khasi/en-kha.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Nyishi/njz-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Nyishi/en-njz.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-2/Bodo/bodo-en.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-2/Bodo/en-bodo.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-2/Kokborok/en-trp.txt\n/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-2/Kokborok/trp-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Mizo/en-lus.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Mizo/lus-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Assamese/as-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Assamese/en-as.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Manipuri/en-mni.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Manipuri/mni-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Khasi/kha-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Khasi/en-kha.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Nyishi/njz-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-1/Nyishi/en-njz.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-2/Bodo/bodo-en.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-2/Bodo/en-bodo.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-2/Kokborok/en-trp.txt\n/kaggle/input/emnlp-test-dataser-2025/indicMT_testset2025_release/Category-2/Kokborok/trp-en.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate bitsandbytes peft evaluate sacrebleu\n!pip install -U bitsandbytes\n!pip install datasets pandas sacremoses fasttext sentence-transformers sentencepiece scikit-learn\n!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n!pip install spacy indic-transliteration\n!python -m spacy download en_core_web_sm \n!pip install indic-nlp-library ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:16:07.608851Z","iopub.execute_input":"2025-06-09T19:16:07.609244Z","iopub.status.idle":"2025-06-09T19:17:59.192253Z","shell.execute_reply.started":"2025-06-09T19:16:07.609223Z","shell.execute_reply":"2025-06-09T19:17:59.191516Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.0)\nRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\nRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n--2025-06-09 19:17:40--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.108, 3.163.189.96, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 938013 (916K) [binary/octet-stream]\nSaving to: ‘lid.176.ftz’\n\nlid.176.ftz         100%[===================>] 916.03K  --.-KB/s    in 0.04s   \n\n2025-06-09 19:17:40 (25.1 MB/s) - ‘lid.176.ftz’ saved [938013/938013]\n\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\nCollecting indic-transliteration\n  Downloading indic_transliteration-2.3.69-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nCollecting backports.functools-lru-cache (from indic-transliteration)\n  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (2024.11.6)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.10.2)\nCollecting roman (from indic-transliteration)\n  Downloading roman-5.0-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading indic_transliteration-2.3.69-py3-none-any.whl (155 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\nDownloading roman-5.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: roman, backports.functools-lru-cache, indic-transliteration\nSuccessfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.69 roman-5.0\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting indic-nlp-library\n  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\nCollecting sphinx-argparse (from indic-nlp-library)\n  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.2.4)\nCollecting morfessor (from indic-nlp-library)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.1)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\nRequirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->indic-nlp-library) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.4.26)\nDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\nInstalling collected packages: morfessor, sphinx-argparse, indic-nlp-library\nSuccessfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, \n                          Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq)\nfrom transformers import BitsAndBytesConfig\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport evaluate ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:17:59.193340Z","iopub.execute_input":"2025-06-09T19:17:59.193629Z","iopub.status.idle":"2025-06-09T19:18:23.472934Z","shell.execute_reply.started":"2025-06-09T19:17:59.193597Z","shell.execute_reply":"2025-06-09T19:18:23.472193Z"}},"outputs":[{"name":"stderr","text":"2025-06-09 19:18:11.102796: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749496691.286773      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749496691.341712      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset, Dataset\n\n# Load original CSV\ndataset = load_dataset(\n    'csv',\n    data_files=\"/kaggle/input/emnlp-dataset-2025/English-Assamese Training Data 2025.csv\",\n    split=\"train\"\n)\n\n# Reverse columns: Assamese ← English, English ← Assamese\nreversed_examples = [{\"as\": example[\"as\"], \"en\": example[\"en\"]} for example in dataset]\n\n# Rebuild as a new Dataset with exactly ordered columns\nreversed_dataset = Dataset.from_list(reversed_examples)\n\n# Shuffle and take 100 rows\nsubset = reversed_dataset.shuffle(seed=42).select(range(20000))\n\n# Train-test split\ndataset_split = subset.train_test_split(test_size=0.05)\ntrain_dataset = dataset_split[\"train\"]\ntest_dataset = dataset_split[\"test\"]\n\n# Confirm column order\nprint(train_dataset)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:23.474791Z","iopub.execute_input":"2025-06-09T19:18:23.475324Z","iopub.status.idle":"2025-06-09T19:18:25.809663Z","shell.execute_reply.started":"2025-06-09T19:18:23.475303Z","shell.execute_reply":"2025-06-09T19:18:25.809047Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"609df12dd5884a11ba08ff05f10a9489"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['as', 'en'],\n    num_rows: 900\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"test_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:25.810458Z","iopub.execute_input":"2025-06-09T19:18:25.810726Z","iopub.status.idle":"2025-06-09T19:18:25.815798Z","shell.execute_reply.started":"2025-06-09T19:18:25.810698Z","shell.execute_reply":"2025-06-09T19:18:25.815004Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['as', 'en'],\n    num_rows: 100\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n\nfactory = IndicNormalizerFactory()\nnormalizer = factory.get_normalizer(\"as\")\n\ndef normalize_assamese(batch):\n    return {'as': [normalizer.normalize(x) for x in batch['as']], 'en': batch['en']}\n\ntrain_dataset = train_dataset.map(normalize_assamese, batched=True)\ntest_dataset=test_dataset.map(normalize_assamese, batched=True)\n\ndef remove_duplicates(batch):\n    seen = set()\n    filt = []\n    for en, as_ in zip(batch['en'], batch['as']):\n        key = (en, as_)\n        if key not in seen:\n            seen.add(key)\n            filt.append(True)\n        else:\n            filt.append(False)\n    return {\"keep\": filt}\n\ntrain_dataset = train_dataset.map(remove_duplicates, batched=True).filter(lambda x: x['keep'])\ntest_dataset = test_dataset.map(remove_duplicates, batched=True).filter(lambda x: x['keep'])\n\nprint(f\"After removing duplicates: {len(train_dataset)}\")\ntrain_dataset[:5]\n\ndef ratio_filter(en, as_):\n    ratio = len(en.split()) / max(1, len(as_.split()))\n    return 0.5 <= ratio <= 2.0\n\ntrain_dataset = train_dataset.filter(lambda x: ratio_filter(x['en'], x['as']))\ntest_dataset = test_dataset.filter(lambda x: ratio_filter(x['en'], x['as']))\n\nimport string\n\ndef preprocess_text(batch):\n    # Create a translation table to remove punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    \n    # Process English text\n    processed_en = [text.translate(translator) for text in batch['en']]\n    \n    # Process Assamese text (assuming 'as' is the key for Assamese text)\n    processed_as = [text.lower().translate(translator) for text in batch['as']]\n    \n    return {'en': processed_en, 'as': processed_as}\n\n# Then apply text preprocessing\ntrain_dataset = train_dataset.map(preprocess_text, batched=True)\ntest_dataset = test_dataset.map(preprocess_text, batched=True)\n\nprint(f\"After preprocessing: {len(train_dataset)}\")\ntrain_dataset[:5]\n\nimport unicodedata\n\ndef to_halfwidth(text):\n    return unicodedata.normalize('NFKC', text)\n\ntrain_dataset = train_dataset.map(lambda x: {\n    'en': to_halfwidth(x['en']),\n    'as': to_halfwidth(x['as'])\n})\ntest_dataset = test_dataset.map(lambda x: {\n    'en': to_halfwidth(x['en']),\n    'as': to_halfwidth(x['as'])\n})\nprint(test_dataset[:3])\nprint(train_dataset[:3])\n\nimport fasttext\n\n# Make sure lid.176.ftz is in /kaggle/working or input path\nft_model = fasttext.load_model(\"lid.176.ftz\")\n\ndef lang_filter(text, lang):\n    pred = ft_model.predict(text.replace(' ', '_'), k=1)\n    code = pred[0][0].replace('__label__', '')\n    return code == lang\n\ntrain_dataset = train_dataset.filter(lambda x: lang_filter(x['en'], 'en') and lang_filter(x['as'], 'as'))\ntest_dataset = test_dataset.filter(lambda x: lang_filter(x['en'], 'en') and lang_filter(x['as'], 'as'))\n\nprint(f\"After language filtering: {len(train_dataset)}\")\ntrain_dataset[:3]\n\ntrain_dataset = train_dataset.remove_columns('keep')\ntest_dataset = test_dataset.remove_columns('keep')\n\ndef length_filter(en, as_):\n    return len(en.split()) <= 150 and len(as_.split()) <= 150\n\ntrain_dataset = train_dataset.filter(lambda x: length_filter(x['en'], x['as']))\ntest_dataset = test_dataset.filter(lambda x: length_filter(x['en'], x['as']))\n\nprint(f\"After length filtering: {len(train_dataset)}\")\ntrain_dataset[:3] \n\nimport string\n\ntranslator = str.maketrans('', '', string.punctuation)\n\ndef remove_punctuation(batch):\n    return {\n        'en': [text.translate(translator) for text in batch['en']],\n        'as': [text.translate(translator) for text in batch['as']],\n    }\n\n# Apply to both train and test datasets\ntrain_dataset = train_dataset.map(remove_punctuation, batched=True)\ntest_dataset = test_dataset.map(remove_punctuation, batched=True)\n\ndef clean_whitespace(batch):\n    return {\n        'en': [x.strip().replace(\"  \", \" \") for x in batch['en']],\n        'as': [x.strip().replace(\"  \", \" \") for x in batch['as']]\n    }\n\ntrain_dataset = train_dataset.map(clean_whitespace, batched=True)\ntest_dataset=test_dataset.map(clean_whitespace,batched=True)\n\nimport pandas as pd\n\ndata = pd.DataFrame(train_dataset[:10])  # Load first 10 rows\nprint(data['en'][3])\nprint(data['as'][3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:25.816558Z","iopub.execute_input":"2025-06-09T19:18:25.816726Z","iopub.status.idle":"2025-06-09T19:18:26.365694Z","shell.execute_reply.started":"2025-06-09T19:18:25.816712Z","shell.execute_reply":"2025-06-09T19:18:26.364915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70e314584c554753bb5ae46ff78ae7f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba4f0f2603a46bb8438a12c42188b97"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857491ea7064444cbc795da51fb9230c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2b61d1849e421e9994c9d66a77f727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d9f5937ff5f4f3c9a428a85ab3027cc"}},"metadata":{}},{"name":"stdout","text":"After removing duplicates: 900\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/900 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de4f67e96928496e8ceb6120e5e64be9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324d2fc23fdd49d98534a9ae2123af34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/857 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec22908d361348d6beb6235dedbc7fd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/96 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"59a7cb19b0d74e639be15488ef414857"}},"metadata":{}},{"name":"stdout","text":"After preprocessing: 857\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/857 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8d2243e7c1d4f86a93a708e20b0eeb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/96 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e62881d0baf4986a13ee045604a8ff2"}},"metadata":{}},{"name":"stdout","text":"{'as': ['যিহোৱাই মোচি আৰু হাৰোণৰ দ্বাৰা ইস্ৰায়েল জাতিক পথ প্ৰদৰ্শক আৰু মিৰিয়মক ইস্ৰায়েলৰ স্ত্ৰীবিলাকক বিজয়ী নীত্য কৰাত পৰিচলনা কৰিবলৈ ব্যৱহাৰ কৰিলে ।', 'কুমাৰাকমৰ বতৰলৈ চাই আগতীয়া জুনৰ পৰা আগষ্টৰ মাজভাগলৈ  নৱেম্বৰৰ পৰা মাৰ্চলৈ মাহকেইটা সৰ্বোত্তম বুলি ধাৰণা কৰা হয় ।', 'আৰু যিহোচূৱাই তেওঁলোকৰে সৈতে সন্ধি স্থাপন কৰি তেওঁলোকে যেন জীয়াই থাকে  এনে নিয়ম কৰিলে আৰু লোক সকলৰ অধ্যক্ষ সকলে তেওঁলোকৰ আগত শপত খালে ।'], 'en': ['Moses and Aaron were used to guide the nation  and Miriam led the women of Israel in a victory dance ', 'In Kumarakom the monsoon are early June to mid August  November to March considered the best months ', 'And Joshua made peace with them  and made a league with them  to let them live and the princes of the congregation sware unto them '], 'keep': [True, True, True]}\n{'as': ['কাৰণ যিহোৱা মহান আৰু অতি প্ৰশংসনীয়  আৰু আন সকলো দেৱতা বোৰতকৈ তেওঁ ভয়ানক ।', 'যেতিয়া আপোনালোকৰ গৰু ছাগলী  ভেড়া জাকৰ বৃদ্ধি পাব  আপোনালোকৰ অধিক সোণ ৰূপ হব আৰু আপোনালোকৰ সকলো সম্পত্তি বৃদ্ধি পাব ', 'বাবিলৰ ৰজাই চিদিকিয়াৰ পুতেকবিলাকক তেওঁৰ চকুৰ আগতে বধ কৰিলে । আৰু যিহূদাৰ আটাই প্ৰধান লোককো ৰিব্লাত বধ কৰিলে ।'], 'en': ['For great is the Lord  and greatly to be praised he also is to be feared above all gods ', 'And when thy herds and thy flocks multiply  and thy silver and thy gold is multiplied  and all that thou hast is multiplied ', 'And the king of Babylon slew the sons of Zedekiah before his eyes   he slew also all the princes of Judah in Riblah '], 'keep': [True, True, True]}\n","output_type":"stream"},{"name":"stderr","text":"Parameter 'function'=<function <lambda> at 0x788d753e99e0> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/857 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82eeccf90684492db69c66de7520da1d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/96 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11320afec8fa4b38a3a9ae15a7972073"}},"metadata":{}},{"name":"stdout","text":"After language filtering: 689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34f613744b54495a832f13948597d6cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/80 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9dd3f35a5ea4ff88b627ccfa2817763"}},"metadata":{}},{"name":"stdout","text":"After length filtering: 689\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dafaeb3d00214061a689d5e02d1f385d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/80 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43bca90ff4034a05bb66f65366897d7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c61b976561e41e7921dbf2ff922c289"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/80 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e68913c00a4a20b7a45c9940edd52c"}},"metadata":{}},{"name":"stdout","text":"Does a grasshopper have cause to vaunt its prowess just because it can hop a little farther than other grasshoppers\nএটা ফৰিঙে আনটো ফৰিঙৰ তুলনাত নিজকে মহান বুলি ভাবিব পাৰেনে\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"Train samples:\")\nfor i in range(3):\n    print(f\"EN: {train_dataset[i]['en']}\")\n    print(f\"AS: {train_dataset[i]['as']}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:26.366440Z","iopub.execute_input":"2025-06-09T19:18:26.366713Z","iopub.status.idle":"2025-06-09T19:18:26.371839Z","shell.execute_reply.started":"2025-06-09T19:18:26.366690Z","shell.execute_reply":"2025-06-09T19:18:26.371195Z"}},"outputs":[{"name":"stdout","text":"Train samples:\nEN: And when thy herds and thy flocks multiply and thy silver and thy gold is multiplied and all that thou hast is multiplied\nAS: যেতিয়া আপোনালোকৰ গৰু ছাগলী ভেড়া জাকৰ বৃদ্ধি পাব আপোনালোকৰ অধিক সোণ ৰূপ হব আৰু আপোনালোকৰ সকলো সম্পত্তি বৃদ্ধি পাব\n\nEN: That I may make it manifest as I ought to speak\nAS: আপোনালোকৰ বাৰ্তালাপ যেন সদায় অনুগ্ৰহযুক্ত হৈ থাকক আৰু আস্বাদযুক্ত লোণৰদৰে কোন জনক কেনেকৈ উত্তৰ দিব লাগে সেই বিষয়ে যেন আপোনালোকে জানি লওঁক ।\n\nEN: In the midst of material abundance many barely eke out a living\nAS: বহুতে ভৌতিকভাৱে সমৃদ্ধিশীল হোৱা পৰিস্থিতিৰ মাজত থকাৰ স্বত্বেও জীয়াই থাকিবলৈ সাধাৰণভাৱে সংগ্ৰাম কৰিবলগীয়া হৈছে ।\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"train_dataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:26.372593Z","iopub.execute_input":"2025-06-09T19:18:26.372823Z","iopub.status.idle":"2025-06-09T19:18:26.390879Z","shell.execute_reply.started":"2025-06-09T19:18:26.372799Z","shell.execute_reply":"2025-06-09T19:18:26.390194Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'as': 'যেতিয়া আপোনালোকৰ গৰু ছাগলী ভেড়া জাকৰ বৃদ্ধি পাব আপোনালোকৰ অধিক সোণ ৰূপ হব আৰু আপোনালোকৰ সকলো সম্পত্তি বৃদ্ধি পাব',\n 'en': 'And when thy herds and thy flocks multiply and thy silver and thy gold is multiplied and all that thou hast is multiplied'}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n\nmodel_name = \"facebook/nllb-200-3.3B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Set target language code (must match NLLB language codes)\ntgt_lang = \"eng_Latn\"\nforced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n\n# Configure 8-bit quantization\nbnb_config = BitsAndBytesConfig(load_in_8bit=True)\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    quantization_config=bnb_config,\n    forced_bos_token_id=forced_bos_token_id\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:18:26.391707Z","iopub.execute_input":"2025-06-09T19:18:26.391942Z","iopub.status.idle":"2025-06-09T19:21:39.985718Z","shell.execute_reply.started":"2025-06-09T19:18:26.391922Z","shell.execute_reply":"2025-06-09T19:21:39.985196Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351d15b7bd704aeebaf690f3e6b8f375"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1def425a43df41ecadab51cc651d9c9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6762cb7d3ab841a78cb02f4059d38fac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82bdf29397fc479f96d4804b44969bd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c0c5676c4b4d49ad6787c362907e53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/90.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c37c78db41c4176962948d89fd38c16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c9adf72a1c94646bd27c4214b899e94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00003.bin:   0%|          | 0.00/6.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"071fb7b9b7a34a2e8d6939cff4013333"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00003.bin:   0%|          | 0.00/8.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d52a5353607b4b6cb2179a6faa6539e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00003.bin:   0%|          | 0.00/2.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a63452fe12c34b75ab3cfa090c5fa807"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/94.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ead1f429674bfbb08de4593d2e2c09"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"918ac00625034cf08a81bdfdef7d87d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41efee6f2016473485987ed597402bd2"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def preprocess_examples(examples):\n    # Set source and target languages\n    tokenizer.src_lang = \"asm_Beng\"\n    tokenizer.tgt_lang = \"eng_Latn\"\n\n    # Tokenize inputs and targets\n    model_inputs = tokenizer(\n        examples[\"as\"],\n        max_length=256,\n        padding=\"longest\",\n        truncation=True\n    )\n    \n    labels = tokenizer(\n        examples[\"en\"],\n        max_length=256,\n        padding=\"longest\",\n        truncation=True\n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n\n# Apply to datasets\ntrain_dataset = train_dataset.map(preprocess_examples, batched=True, remove_columns=train_dataset.column_names)\ntest_dataset = test_dataset.map(preprocess_examples, batched=True, remove_columns=test_dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:39.987989Z","iopub.execute_input":"2025-06-09T19:21:39.988221Z","iopub.status.idle":"2025-06-09T19:21:40.439907Z","shell.execute_reply.started":"2025-06-09T19:21:39.988204Z","shell.execute_reply":"2025-06-09T19:21:40.439099Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/689 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d84fef06392544c8ad95ef805bba4893"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/80 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7acb11ddb204388ba900b247a4d44c7"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=64,\n    lora_alpha=128,\n    lora_dropout=0.1,\n    bias=\"none\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  \n    #use_dora=True\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\ndevice = torch.device(\"cuda\")\n\nmodel=model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:40.440735Z","iopub.execute_input":"2025-06-09T19:21:40.441433Z","iopub.status.idle":"2025-06-09T19:21:41.802258Z","shell.execute_reply.started":"2025-06-09T19:21:40.441414Z","shell.execute_reply":"2025-06-09T19:21:41.801109Z"}},"outputs":[{"name":"stdout","text":"trainable params: 56,623,104 || all params: 3,401,486,336 || trainable%: 1.6647\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    padding=\"longest\",\n    pad_to_multiple_of=8,\n    label_pad_token_id=-100\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:41.803682Z","iopub.execute_input":"2025-06-09T19:21:41.805496Z","iopub.status.idle":"2025-06-09T19:21:41.810476Z","shell.execute_reply.started":"2025-06-09T19:21:41.805471Z","shell.execute_reply":"2025-06-09T19:21:41.808850Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"bleu_metric = evaluate.load(\"sacrebleu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:41.811527Z","iopub.execute_input":"2025-06-09T19:21:41.811901Z","iopub.status.idle":"2025-06-09T19:21:42.545163Z","shell.execute_reply.started":"2025-06-09T19:21:41.811869Z","shell.execute_reply":"2025-06-09T19:21:42.544629Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b6f98645f66423ab66bd03a853f35f6"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import torch\n\n# Sample Assamese input\nassamese_text = \"চি কৰ্পৰেছন আমেৰিকা যুক্তৰাষ্ট্ৰত প্ৰকল্প ৰূপায়নৰ হেতু আমেৰিকা যুক্তৰাষ্ট্ৰৰ টেক্সাছত গঠন কৰা হৈছে ।\"\n\n# Set tokenizer source and target language\ntokenizer.src_lang = \"asm_Beng\"\ntokenizer.tgt_lang = \"eng_Latn\"\n\n# Tokenize the input\ninputs = tokenizer(\n    assamese_text,\n    return_tensors=\"pt\",\n    padding=True,\n    truncation=True\n).to(model.device)\n\n# Generate output\ntranslated_tokens = model.generate(\n    **inputs,\n    forced_bos_token_id=forced_bos_token_id,\n    max_length=256\n)\n\n# Decode the output\ntranslation = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n\nprint(\"Translated Text:\", translation)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:42.545931Z","iopub.execute_input":"2025-06-09T19:21:42.546675Z","iopub.status.idle":"2025-06-09T19:21:46.336916Z","shell.execute_reply.started":"2025-06-09T19:21:42.546656Z","shell.execute_reply":"2025-06-09T19:21:46.336264Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Translated Text: C Corporation was formed in Texas, United States, to implement projects in the United States.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import transliterate\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds.predictions, eval_preds.label_ids\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    if preds.ndim == 3:\n        preds = np.argmax(preds, axis=-1)\n\n    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n   # decoded_preds = [transliterate(p, sanscript.DEVANAGARI, sanscript.BENGALI) for p in decoded_preds]\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    \n    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:46.337705Z","iopub.execute_input":"2025-06-09T19:21:46.337976Z","iopub.status.idle":"2025-06-09T19:21:46.513334Z","shell.execute_reply.started":"2025-06-09T19:21:46.337948Z","shell.execute_reply":"2025-06-09T19:21:46.512548Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./output\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,\n    num_train_epochs=1,\n    learning_rate=3e-5, \n    warmup_steps=1000,\n    lr_scheduler_type=\"cosine\", \n    logging_steps=500,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n   # save_steps=1000,\n    save_total_limit=2,\n    fp16=True,\n    predict_with_generate=True,\n    report_to=\"none\",\n    optim=\"adamw_torch_fused\",\n    adam_beta1=0.9,\n    adam_beta2=0.98,\n    ddp_find_unused_parameters=False,\n    remove_unused_columns=False,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\nmodel.config.use_cache = False\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:21:46.514267Z","iopub.execute_input":"2025-06-09T19:21:46.514521Z","iopub.status.idle":"2025-06-09T19:25:09.245942Z","shell.execute_reply.started":"2025-06-09T19:21:46.514504Z","shell.execute_reply":"2025-06-09T19:25:09.245358Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4153509896.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='43' max='43' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [43/43 03:19, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>No log</td>\n      <td>7.740397</td>\n      <td>22.442386</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=43, training_loss=9.732076955396076, metrics={'train_runtime': 202.1526, 'train_samples_per_second': 3.408, 'train_steps_per_second': 0.213, 'total_flos': 855023988768768.0, 'train_loss': 9.732076955396076, 'epoch': 0.9885057471264368})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"predictions = trainer.predict(test_dataset) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:25:48.248252Z","iopub.execute_input":"2025-06-09T19:25:48.248752Z","iopub.status.idle":"2025-06-09T19:27:10.309458Z","shell.execute_reply.started":"2025-06-09T19:25:48.248727Z","shell.execute_reply":"2025-06-09T19:27:10.308860Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import numpy as np\n\n# Handle logits or token IDs\nif isinstance(predictions.predictions, tuple):\n    preds = predictions.predictions[0]\nelse:\n    preds = predictions.predictions\n\nif preds.ndim == 3:\n    preds = np.argmax(preds, axis=-1)\n\nlabels = np.where(predictions.label_ids == -100, tokenizer.pad_token_id, predictions.label_ids)\n\ndecoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\ndecoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:27:10.310685Z","iopub.execute_input":"2025-06-09T19:27:10.310960Z","iopub.status.idle":"2025-06-09T19:27:13.313494Z","shell.execute_reply.started":"2025-06-09T19:27:10.310939Z","shell.execute_reply":"2025-06-09T19:27:13.312562Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for ref, pred in zip(decoded_labels[:10], decoded_preds[:10]):\n    print(f\"Actual   : {ref}\")\n    print(f\"Predicted: {pred}\")\n    print(\"-\" * 100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:27:36.986757Z","iopub.execute_input":"2025-06-09T19:27:36.987071Z","iopub.status.idle":"2025-06-09T19:27:36.992045Z","shell.execute_reply.started":"2025-06-09T19:27:36.987048Z","shell.execute_reply":"2025-06-09T19:27:36.991194Z"}},"outputs":[{"name":"stdout","text":"Actual   : Moses and Aaron were used to guide the nation and Miriam led the women of Israel in a victory dance\nPredicted: Jehovah used Moses and Aaron to guide the nation of Israel, and Miriam to guide the women of Israel in their victorious march.\n----------------------------------------------------------------------------------------------------\nActual   : In Kumarakom the monsoon are early June to mid August November to March considered the best months\nPredicted: The best months for the weather in Kumarakom are from early June to mid-August and from November to March.\n----------------------------------------------------------------------------------------------------\nActual   : And Joshua made peace with them and made a league with them to let them live and the princes of the congregation sware unto them\nPredicted: And Joshua made a covenant with them, and made a league with them, to let them live; and the princes of the people swore unto them.\n----------------------------------------------------------------------------------------------------\nActual   : Fit to be subdued or controlled\nPredicted: The Bible says: \"The one who is wise will become wise, but the one who is foolish will become foolish\".\n----------------------------------------------------------------------------------------------------\nActual   : If I regard iniquity in my heart the Lord will not hear me\nPredicted: If I regard iniquity in my heart , the Lord will not hear me .\n----------------------------------------------------------------------------------------------------\nActual   : Through desire a man having separated himself seeketh and intermeddleth with all wisdom\nPredicted: The man who separates himself from others pursues his own interests; he is hostile to all good sense.\n----------------------------------------------------------------------------------------------------\nActual   : Surely they should obey their parents and be interested in learning about spiritual things Deuteronomy 5 16 Ephesians 6 1 3\nPredicted: (Matthew 28:19, 20) The apostle Paul wrote: \"The love the Christ has for you is a perfect bond of union with God\". (1 Corinthians 14:33) The apostle Paul wrote: \"I am not ignorant of any of these things, but I am united with you in the knowledge that God loves the united as I have loved the united\".\n----------------------------------------------------------------------------------------------------\nActual   : Through the Bible Jehovah sheds light on his purposes and tells us how we can do his will\nPredicted: (Psalm 119:105) We can be sure that Jehovah will not allow us to be distracted by our own bad habits.\n----------------------------------------------------------------------------------------------------\nActual   : The Three world Hall which is located on the highest point of Potala Palace is the holy shrine of Chinese Emperors\nPredicted: The Three Worlds, located at the very top of the Pala Palau, is considered the religious site of the emperors of the Chinese Empire.\n----------------------------------------------------------------------------------------------------\nActual   : Lot was  greatly distressed  because of the depravity of Sodom\nPredicted: Lot, for example, was greatly distressed by the immoral conduct of Sodom.\n----------------------------------------------------------------------------------------------------\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\ntrainer.save_model(\"./final_model\")\ntokenizer.save_pretrained(\"./final_model\")\n\n# Configure 4-bit quantization\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\n# Load model and tokenizer from Kaggle input directory\nmodel_path = \"./final_model\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    #quantization_config=quant_config,\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n\n# Set target language\ntgt_lang = \"eng_Latn\"\nforced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\nmodel.config.forced_bos_token_id = forced_bos_token_id\nmodel.config.use_cache = True\n\n# Load Manipuri test sentences\ntest_file = \"/kaggle/input/emnlp-test-dataset-2025/indicMT_testset2025_release/Category-1/Assamese/as-en.txt\"\nwith open(test_file, \"r\", encoding=\"utf-8\") as f:\n    manipuri_sentences = [line.split(\"\\t\")[0].strip() for line in f if line.strip()]\n\nfrom tqdm import tqdm  \n\neng_predictions = []\nfor sentence in tqdm(manipuri_sentences, desc=\"Translating\"):\n    inputs = tokenizer(\n        f\"asm_Beng{sentence}\",\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=256\n    ).to(model.device)\n\n    outputs = model.generate(\n        **inputs,\n        forced_bos_token_id=forced_bos_token_id,\n        max_length=256,\n        num_beams=5\n    )\n    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    eng_predictions.append(decoded)\n\n# Save predictions\nwith open(\"myresult.txt\", \"w\", encoding=\"utf-8\") as f:\n    for pred in eng_predictions:\n        f.write(pred + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:25:39.073053Z","iopub.status.idle":"2025-06-09T19:25:39.073305Z","shell.execute_reply.started":"2025-06-09T19:25:39.073181Z","shell.execute_reply":"2025-06-09T19:25:39.073196Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\n# Zip the folder\nshutil.make_archive(\"/kaggle/working/final_model\", 'zip', \"./final_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-09T19:30:00.676284Z","iopub.execute_input":"2025-06-09T19:30:00.676597Z","iopub.status.idle":"2025-06-09T19:30:12.735221Z","shell.execute_reply.started":"2025-06-09T19:30:00.676578Z","shell.execute_reply":"2025-06-09T19:30:12.734594Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/final_model.zip'"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}