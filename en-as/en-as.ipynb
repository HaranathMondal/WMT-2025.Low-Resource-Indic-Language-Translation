{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12126329,"sourceType":"datasetVersion","datasetId":7635690},{"sourceId":12126344,"sourceType":"datasetVersion","datasetId":7635703},{"sourceId":432131,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":352268,"modelId":373542}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:01:44.465405Z","iopub.execute_input":"2025-06-11T12:01:44.465657Z","iopub.status.idle":"2025-06-11T12:01:45.775737Z","shell.execute_reply.started":"2025-06-11T12:01:44.465638Z","shell.execute_reply":"2025-06-11T12:01:45.775045Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/engtasm/English-Assamese Training Data 2025.csv\n/kaggle/input/eng-asm/transformers/default/1/adapter_model.safetensors\n/kaggle/input/eng-asm/transformers/default/1/training_args.bin\n/kaggle/input/eng-asm/transformers/default/1/adapter_config.json\n/kaggle/input/eng-asm/transformers/default/1/README.md\n/kaggle/input/eng-asm/transformers/default/1/tokenizer_config.json\n/kaggle/input/eng-asm/transformers/default/1/special_tokens_map.json\n/kaggle/input/eng-asm/transformers/default/1/sentencepiece.bpe.model\n/kaggle/input/eng-asm/transformers/default/1/added_tokens.json\n/kaggle/input/engtasmtest/en-as.txt\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q transformers datasets accelerate bitsandbytes peft evaluate sacrebleu\n!pip install -U bitsandbytes\n!pip install datasets pandas sacremoses fasttext sentence-transformers sentencepiece scikit-learn\n!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\n!pip install spacy indic-transliteration\n!python -m spacy download en_core_web_sm \n!pip install indic-nlp-library ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:01:50.457884Z","iopub.execute_input":"2025-06-11T12:01:50.458638Z","iopub.status.idle":"2025-06-11T12:03:40.779252Z","shell.execute_reply.started":"2025-06-11T12:01:50.458599Z","shell.execute_reply":"2025-06-11T12:03:40.778524Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\nRequirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nCollecting sacremoses\n  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\nRequirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacremoses) (2024.11.6)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.5.0)\nRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\nRequirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sacremoses\nSuccessfully installed sacremoses-0.1.1\n--2025-06-11 12:03:20--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.ftz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.164.78.81, 18.164.78.121, 18.164.78.72, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.164.78.81|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 938013 (916K) [binary/octet-stream]\nSaving to: ‘lid.176.ftz’\n\nlid.176.ftz         100%[===================>] 916.03K  --.-KB/s    in 0.05s   \n\n2025-06-11 12:03:20 (16.6 MB/s) - ‘lid.176.ftz’ saved [938013/938013]\n\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\nCollecting indic-transliteration\n  Downloading indic_transliteration-2.3.69-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nCollecting backports.functools-lru-cache (from indic-transliteration)\n  Downloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (2024.11.6)\nRequirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from indic-transliteration) (0.10.2)\nCollecting roman (from indic-transliteration)\n  Downloading roman-5.0-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.4.26)\nRequirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading indic_transliteration-2.3.69-py3-none-any.whl (155 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/155.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading backports.functools_lru_cache-2.0.0-py2.py3-none-any.whl (6.7 kB)\nDownloading roman-5.0-py3-none-any.whl (5.5 kB)\nInstalling collected packages: roman, backports.functools-lru-cache, indic-transliteration\nSuccessfully installed backports.functools-lru-cache-2.0.0 indic-transliteration-2.3.69 roman-5.0\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting indic-nlp-library\n  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\nCollecting sphinx-argparse (from indic-nlp-library)\n  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (0.2.4)\nCollecting morfessor (from indic-nlp-library)\n  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from indic-nlp-library) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->indic-nlp-library) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->indic-nlp-library) (2025.2)\nRequirement already satisfied: sphinx>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (8.2.3)\nRequirement already satisfied: docutils>=0.19 in /usr/local/lib/python3.11/dist-packages (from sphinx-argparse->indic-nlp-library) (0.21.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.17.0)\nRequirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\nRequirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\nRequirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\nRequirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.6)\nRequirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.19.1)\nRequirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\nRequirement already satisfied: babel>=2.13 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.17.0)\nRequirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.0)\nRequirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\nRequirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\nRequirement already satisfied: roman-numerals-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.0)\nRequirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.11/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (25.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->indic-nlp-library) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->indic-nlp-library) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->indic-nlp-library) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2025.4.26)\nDownloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\nDownloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\nInstalling collected packages: morfessor, sphinx-argparse, indic-nlp-library\nSuccessfully installed indic-nlp-library-0.92 morfessor-2.0.6 sphinx-argparse-0.5.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, \n                          Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq)\nfrom transformers import BitsAndBytesConfig\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport evaluate ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:03:50.051449Z","iopub.execute_input":"2025-06-11T12:03:50.052072Z","iopub.status.idle":"2025-06-11T12:04:15.598757Z","shell.execute_reply.started":"2025-06-11T12:03:50.052040Z","shell.execute_reply":"2025-06-11T12:04:15.598200Z"}},"outputs":[{"name":"stderr","text":"2025-06-11 12:04:02.451001: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749643442.673020      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749643442.735897      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"dataset = load_dataset(\n    'csv', \n    data_files=\"/kaggle/input/engtasm/English-Assamese Training Data 2025.csv\", \n    split=\"train\"\n)\n\nsubset = dataset.shuffle(seed=42).select(range(30000))\n\ndataset_split = subset.train_test_split(test_size=0.1) \ntrain_dataset = dataset_split['train']\ntest_dataset = dataset_split['test']\n\nprint(f\"Train examples: {len(train_dataset)}, Test examples: {len(test_dataset)}\")  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:16:53.704478Z","iopub.execute_input":"2025-06-11T05:16:53.704783Z","iopub.status.idle":"2025-06-11T05:16:53.843656Z","shell.execute_reply.started":"2025-06-11T05:16:53.704763Z","shell.execute_reply":"2025-06-11T05:16:53.843075Z"}},"outputs":[{"name":"stdout","text":"Train examples: 27000, Test examples: 3000\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n\nfactory = IndicNormalizerFactory()\nnormalizer = factory.get_normalizer(\"as\")\n\ndef normalize_assamese(batch):\n    return {'as': [normalizer.normalize(x) for x in batch['as']], 'en': batch['en']}\n\ntrain_dataset = train_dataset.map(normalize_assamese, batched=True)\ntest_dataset=test_dataset.map(normalize_assamese, batched=True)\n\ndef remove_duplicates(batch):\n    seen = set()\n    filt = []\n    for en, as_ in zip(batch['en'], batch['as']):\n        key = (en, as_)\n        if key not in seen:\n            seen.add(key)\n            filt.append(True)\n        else:\n            filt.append(False)\n    return {\"keep\": filt}\n\ntrain_dataset = train_dataset.map(remove_duplicates, batched=True).filter(lambda x: x['keep'])\ntest_dataset = test_dataset.map(remove_duplicates, batched=True).filter(lambda x: x['keep'])\n\nprint(f\"After removing duplicates: {len(train_dataset)}\")\ntrain_dataset[:5]\n\ndef ratio_filter(en, as_):\n    ratio = len(en.split()) / max(1, len(as_.split()))\n    return 0.5 <= ratio <= 2.0\n\ntrain_dataset = train_dataset.filter(lambda x: ratio_filter(x['en'], x['as']))\ntest_dataset = test_dataset.filter(lambda x: ratio_filter(x['en'], x['as']))\n\nimport string\n\ndef preprocess_text(batch):\n    # Create a translation table to remove punctuation\n    translator = str.maketrans('', '', string.punctuation)\n    \n    # Process English text\n    processed_en = [text.lower().translate(translator) for text in batch['en']]\n    \n    # Process Assamese text (assuming 'as' is the key for Assamese text)\n    processed_as = [text.lower().translate(translator) for text in batch['as']]\n    \n    return {'en': processed_en, 'as': processed_as}\n\n# Then apply text preprocessing\ntrain_dataset = train_dataset.map(preprocess_text, batched=True)\ntest_dataset = test_dataset.map(preprocess_text, batched=True)\n\nprint(f\"After preprocessing: {len(train_dataset)}\")\ntrain_dataset[:5]\n\nimport unicodedata\n\ndef to_halfwidth(text):\n    return unicodedata.normalize('NFKC', text)\n\ntrain_dataset = train_dataset.map(lambda x: {\n    'en': to_halfwidth(x['en']),\n    'as': to_halfwidth(x['as'])\n})\ntest_dataset = test_dataset.map(lambda x: {\n    'en': to_halfwidth(x['en']),\n    'as': to_halfwidth(x['as'])\n})\nprint(test_dataset[:3])\nprint(train_dataset[:3])\n\nimport fasttext\n\n# Make sure lid.176.ftz is in /kaggle/working or input path\nft_model = fasttext.load_model(\"lid.176.ftz\")\n\ndef lang_filter(text, lang):\n    pred = ft_model.predict(text.replace(' ', '_'), k=1)\n    code = pred[0][0].replace('__label__', '')\n    return code == lang\n\ntrain_dataset = train_dataset.filter(lambda x: lang_filter(x['en'], 'en') and lang_filter(x['as'], 'as'))\ntest_dataset = test_dataset.filter(lambda x: lang_filter(x['en'], 'en') and lang_filter(x['as'], 'as'))\n\nprint(f\"After language filtering: {len(train_dataset)}\")\ntrain_dataset[:3]\n\ntrain_dataset = train_dataset.remove_columns('keep')\ntest_dataset = test_dataset.remove_columns('keep')\n\ndef length_filter(en, as_):\n    return len(en.split()) <= 150 and len(as_.split()) <= 150\n\ntrain_dataset = train_dataset.filter(lambda x: length_filter(x['en'], x['as']))\ntest_dataset = test_dataset.filter(lambda x: length_filter(x['en'], x['as']))\n\nprint(f\"After length filtering: {len(train_dataset)}\")\ntrain_dataset[:3] \n\nimport string\n\ntranslator = str.maketrans('', '', string.punctuation)\n\ndef remove_punctuation(batch):\n    return {\n        'en': [text.translate(translator) for text in batch['en']],\n        'as': [text.translate(translator) for text in batch['as']],\n    }\n\n# Apply to both train and test datasets\ntrain_dataset = train_dataset.map(remove_punctuation, batched=True)\ntest_dataset = test_dataset.map(remove_punctuation, batched=True)\n\ndef clean_whitespace(batch):\n    return {\n        'en': [x.strip().replace(\"  \", \" \") for x in batch['en']],\n        'as': [x.strip().replace(\"  \", \" \") for x in batch['as']]\n    }\n\ntrain_dataset = train_dataset.map(clean_whitespace, batched=True)\ntest_dataset=test_dataset.map(clean_whitespace,batched=True)\n\nimport pandas as pd\n\ndata = pd.DataFrame(train_dataset[:10])  # Load first 10 rows\nprint(data['en'][3])\nprint(data['as'][3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:17:00.403333Z","iopub.execute_input":"2025-06-11T05:17:00.403640Z","iopub.status.idle":"2025-06-11T05:17:07.390153Z","shell.execute_reply.started":"2025-06-11T05:17:00.403618Z","shell.execute_reply":"2025-06-11T05:17:07.389344Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb4cdd483cb14a08b02249ab123cf1c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c12e762ba9d041e384a7893c473dcc0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"952582fabfd849ca9f2457dea7ca003e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/27000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f215606ac814ef78bc2916addb5d3ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e991e90dda4e496b9368dd46d48eaaf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc7c2ab40a6246dfb9f0c71d90ab7dc4"}},"metadata":{}},{"name":"stdout","text":"After removing duplicates: 27000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/27000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a9d78a5810442bf9bfb1b1d2be72f5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599db36fe6e549429cdc47395f5ef0f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25575 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d12eee7d8544178cc5d52f98aabcde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2871 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ec12b6412454221962de17e6178f597"}},"metadata":{}},{"name":"stdout","text":"After preprocessing: 25575\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25575 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9a2ce5789948198c573a0684b76caa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2871 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7f7eddda1b479ea54f7a23b7899f43"}},"metadata":{}},{"name":"stderr","text":"Parameter 'function'=<function <lambda> at 0x7aa92b6d8540> of the transform datasets.arrow_dataset.Dataset.filter@2.0.1 couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n","output_type":"stream"},{"name":"stdout","text":"{'en': ['they took the young men to grind  and the children fell under the wood ', 'change role of a user', 'and they sinned yet more against him by provoking the most high in the wilderness '], 'as': ['ডেকাসকলে জাঁত শিল বলে  আমাৰ লৰাসকলে খৰিৰ ভৰত উজুটি খালে ।', 'ব্য়ৱহাৰকৰ্তাৰ ভূমিকা সলনি কৰক', 'কিন্তু তেওঁলোকে তেওঁৰ বিৰুদ্ধে পাপ কৰিয়েই থাকিল  সর্বোপৰি ঈশ্বৰৰ বিৰুদ্ধে মৰুভূমিত বিদ্রোহ আচৰণ কৰিলে ।'], 'keep': [True, True, True]}\n{'en': ['the prime minister called for discussions on matters such as judicious use of water resources  better technology for storage  and use of latest technology in farming  during this krishi kumbh ', 'to another faith by the same spirit  to another the gifts of healing by the same spirit ', 'my full time service has enriched my life more than any secretarial job ever could have '], 'as': ['কৃষি কুম্ভ অনুষ্ঠানত জলসম্পদৰ উপযুক্ত ব্যৱহাৰ  খাদ্যশস্য মজুত ৰখাৰ ক্ষেত্রত অত্যাধূনিক প্ৰযুক্তিৰ ব্যৱহাৰ আৰু কৃষিখণ্ডত আধুনিক প্ৰযুক্তিৰ ব্যৱহাৰৰ দৰে গুৰুত্বপূর্ণ বিষয়ক লৈ প্ৰধানমন্ত্রীয়ে আলোচনা কৰাৰ আহ্বান জনায় ।', 'কিন্তু সেই একমাত্ৰ আত্মাই যাকে যি বৰ দিবলৈ মন কৰে  সেইদৰে তেওঁক ভাগ বাঁটি দি সকলোকে সাধন কৰিছে ।', 'কিয়নো পূৰ্ণ সময় সেৱাৰ কাৰণে মই জীৱনত ইমানেই আনন্দিত আৰু উন্নত হোৱা অনুভৱ কৰিছোঁ  যি মোক তেনে চাকৰিয়ে কেতিয়াও দিব নোৱাৰিলেহেঁতেন ।'], 'keep': [True, True, True]}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/25575 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d62789b199b040a386d8b936f2863d94"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2871 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdc91e254d4449b8b1e8d646c274979e"}},"metadata":{}},{"name":"stdout","text":"After language filtering: 20829\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/20829 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e67c788adc04f50aca91bb28ef54920"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7257961fd7c543d599d927d09cb2cf91"}},"metadata":{}},{"name":"stdout","text":"After length filtering: 20829\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20829 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b7610f2f8b34cd98efec327cd73447e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e815f8533e34493d8ff37e0d9ecf1f3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20829 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c88ffdd4aee4b3e9fbd060fea215284"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cb10f9f57144016902902ff80eac47f"}},"metadata":{}},{"name":"stdout","text":"3 4  a what happens at a wedding feast in cana\nঈশ্বৰৰ ইচ্ছাক পূৰণ কৰিবলৈ দৃঢ় সংকল্প প্ৰকাশ কৰিলে\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(\"Train samples:\")\nfor i in range(3):\n    print(f\"EN: {train_dataset[i]['en']}\")\n    print(f\"AS: {train_dataset[i]['as']}\")\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:17:16.060851Z","iopub.execute_input":"2025-06-11T05:17:16.061540Z","iopub.status.idle":"2025-06-11T05:17:16.066539Z","shell.execute_reply.started":"2025-06-11T05:17:16.061487Z","shell.execute_reply":"2025-06-11T05:17:16.065773Z"}},"outputs":[{"name":"stdout","text":"Train samples:\nEN: the prime minister called for discussions on matters such as judicious use of water resources better technology for storage and use of latest technology in farming during this krishi kumbh\nAS: কৃষি কুম্ভ অনুষ্ঠানত জলসম্পদৰ উপযুক্ত ব্যৱহাৰ খাদ্যশস্য মজুত ৰখাৰ ক্ষেত্রত অত্যাধূনিক প্ৰযুক্তিৰ ব্যৱহাৰ আৰু কৃষিখণ্ডত আধুনিক প্ৰযুক্তিৰ ব্যৱহাৰৰ দৰে গুৰুত্বপূর্ণ বিষয়ক লৈ প্ৰধানমন্ত্রীয়ে আলোচনা কৰাৰ আহ্বান জনায় ।\n\nEN: my full time service has enriched my life more than any secretarial job ever could have\nAS: কিয়নো পূৰ্ণ সময় সেৱাৰ কাৰণে মই জীৱনত ইমানেই আনন্দিত আৰু উন্নত হোৱা অনুভৱ কৰিছোঁ যি মোক তেনে চাকৰিয়ে কেতিয়াও দিব নোৱাৰিলেহেঁতেন ।\n\nEN: a brutal coarse or ignorant act\nAS: নিষ্ঠুৰ কঠোৰ বা অবিবেচক কাৰ্য্য\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n\nmodel_name = \"facebook/nllb-200-3.3B\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token\n\n# Set target language code (must match NLLB language codes)\ntgt_lang = \"asm_Beng\"\nforced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n\n# Configure 8-bit quantization\nbnb_config = BitsAndBytesConfig(load_in_8bit=True)\n\n# Load the model\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_name,\n    torch_dtype=torch.float16,\n    quantization_config=bnb_config,\n    forced_bos_token_id=forced_bos_token_id\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:17:24.421966Z","iopub.execute_input":"2025-06-11T05:17:24.422234Z","iopub.status.idle":"2025-06-11T05:20:33.639584Z","shell.execute_reply.started":"2025-06-11T05:17:24.422214Z","shell.execute_reply":"2025-06-11T05:20:33.639057Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3710b2c147fc4f64815db78386d6c6fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a64b91317dc40448ca96003e0d40dc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd53f34b425b49e9b55be7a2e8dbfb9f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22c211d61d764b5db9a03faa5061a20a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3c0939fa8b4db9aed8c88f89978b75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/90.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83498530cf824656b80e0a0de2f8817e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3eca58e401b4be3a7017066e5e34b0e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00003.bin:   0%|          | 0.00/8.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90b5f065fa4f4ccab064f71d5f283400"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00003.bin:   0%|          | 0.00/6.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a086f2f37eb46af94d4bb8db2e24539"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00003.bin:   0%|          | 0.00/2.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"657a5d4634d04c48972b57124500deb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/94.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be2f80cc3eb343bfb26da2ca61650ffa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"429d2a90e5ae46a3a068bc37983ac970"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d64091135364b1b8f843e20b52973a5"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"def preprocess_examples(examples):\n    # Set source and target languages\n    tokenizer.src_lang = \"eng_Latn\"\n    tokenizer.tgt_lang = \"asm_Beng\"\n\n    # Tokenize inputs and targets\n    model_inputs = tokenizer(\n        examples[\"en\"],\n        max_length=256,\n        padding=\"longest\",\n        truncation=True\n    )\n    \n    labels = tokenizer(\n        examples[\"as\"],\n        max_length=256,\n        padding=\"longest\",\n        truncation=True\n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\n\n# Apply to datasets\ntrain_dataset = train_dataset.map(preprocess_examples, batched=True, remove_columns=train_dataset.column_names)\ntest_dataset = test_dataset.map(preprocess_examples, batched=True, remove_columns=test_dataset.column_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:21:07.722010Z","iopub.execute_input":"2025-06-11T05:21:07.722693Z","iopub.status.idle":"2025-06-11T05:21:16.923483Z","shell.execute_reply.started":"2025-06-11T05:21:07.722671Z","shell.execute_reply":"2025-06-11T05:21:16.922783Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20829 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d1ee34336f54eef88ed15fbb795dd25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2356 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5b5f49965ab4270bb4c0620c4cb20ce"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    r=64,\n    lora_alpha=128,\n    lora_dropout=0.1,\n    bias=\"none\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  \n    #use_dora=True\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.print_trainable_parameters()\ndevice = torch.device(\"cuda\")\n\nmodel=model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:21:28.361699Z","iopub.execute_input":"2025-06-11T05:21:28.362392Z","iopub.status.idle":"2025-06-11T05:21:29.401788Z","shell.execute_reply.started":"2025-06-11T05:21:28.362367Z","shell.execute_reply":"2025-06-11T05:21:29.401149Z"}},"outputs":[{"name":"stdout","text":"trainable params: 56,623,104 || all params: 3,401,486,336 || trainable%: 1.6647\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=model,\n    padding=\"longest\",\n    pad_to_multiple_of=8,\n    label_pad_token_id=-100\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:21:33.616841Z","iopub.execute_input":"2025-06-11T05:21:33.617553Z","iopub.status.idle":"2025-06-11T05:21:33.621980Z","shell.execute_reply.started":"2025-06-11T05:21:33.617522Z","shell.execute_reply":"2025-06-11T05:21:33.621230Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"bleu_metric = evaluate.load(\"sacrebleu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:21:36.312642Z","iopub.execute_input":"2025-06-11T05:21:36.312918Z","iopub.status.idle":"2025-06-11T05:21:36.823076Z","shell.execute_reply.started":"2025-06-11T05:21:36.312892Z","shell.execute_reply":"2025-06-11T05:21:36.822310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ffb6906c7254e449dbefb7637d8ea4a"}},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from indic_transliteration import sanscript\nfrom indic_transliteration.sanscript import transliterate\n\ndef postprocess_text(preds, labels):\n    preds = [pred.strip() for pred in preds]\n    labels = [[label.strip()] for label in labels]\n    return preds, labels\n\ndef compute_metrics(eval_preds):\n    preds, labels = eval_preds.predictions, eval_preds.label_ids\n    if isinstance(preds, tuple):\n        preds = preds[0]\n    if preds.ndim == 3:\n        preds = np.argmax(preds, axis=-1)\n\n    labels = np.where(labels == -100, tokenizer.pad_token_id, labels)\n    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    decoded_preds = [transliterate(p, sanscript.DEVANAGARI, sanscript.BENGALI) for p in decoded_preds]\n    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n    \n    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n    return {\"bleu\": result[\"score\"]}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:21:46.865365Z","iopub.execute_input":"2025-06-11T05:21:46.866355Z","iopub.status.idle":"2025-06-11T05:21:47.032452Z","shell.execute_reply.started":"2025-06-11T05:21:46.866331Z","shell.execute_reply":"2025-06-11T05:21:47.031816Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./output\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=8,\n    gradient_accumulation_steps=2,\n    num_train_epochs=1,\n    learning_rate=3e-5, \n    warmup_steps=1000,\n    lr_scheduler_type=\"cosine\", \n    logging_steps=500,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n   # save_steps=1000,\n    save_total_limit=2,\n    fp16=True,\n    predict_with_generate=True,\n    report_to=\"none\",\n    optim=\"adamw_torch_fused\",\n    adam_beta1=0.9,\n    adam_beta2=0.98,\n    ddp_find_unused_parameters=False,\n    remove_unused_columns=False,\n    load_best_model_at_end=True,\n    metric_for_best_model=\"bleu\",\n    greater_is_better=True,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics\n)\n\nmodel.config.use_cache = False\n\n# trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:22:05.984008Z","iopub.execute_input":"2025-06-11T05:22:05.984567Z","iopub.status.idle":"2025-06-11T05:22:06.055113Z","shell.execute_reply.started":"2025-06-11T05:22:05.984545Z","shell.execute_reply":"2025-06-11T05:22:06.054544Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1960032874.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\nNo label_names provided for model class `PeftModelForSeq2SeqLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T05:22:19.768261Z","iopub.execute_input":"2025-06-11T05:22:19.768963Z","iopub.status.idle":"2025-06-11T07:22:23.695746Z","shell.execute_reply.started":"2025-06-11T05:22:19.768937Z","shell.execute_reply":"2025-06-11T07:22:23.695116Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1302' max='1302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1302/1302 1:59:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>5.433600</td>\n      <td>5.098196</td>\n      <td>14.356930</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1302, training_loss=6.822598365045363, metrics={'train_runtime': 7203.4135, 'train_samples_per_second': 2.892, 'train_steps_per_second': 0.181, 'total_flos': 2.2101375895732224e+16, 'train_loss': 6.822598365045363, 'epoch': 1.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T07:56:10.783162Z","iopub.execute_input":"2025-06-11T07:56:10.783753Z","iopub.status.idle":"2025-06-11T09:50:26.765986Z","shell.execute_reply.started":"2025-06-11T07:56:10.783734Z","shell.execute_reply":"2025-06-11T09:50:26.765405Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/bitsandbytes/autograd/_functions.py:185: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1302' max='1302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1302/1302 1:54:11, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.965400</td>\n      <td>4.970937</td>\n      <td>15.406525</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1302, training_loss=4.97460459344398, metrics={'train_runtime': 6855.4225, 'train_samples_per_second': 3.038, 'train_steps_per_second': 0.19, 'total_flos': 2.2101375895732224e+16, 'train_loss': 4.97460459344398, 'epoch': 1.0})"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"trainer.save_model(\"./final_model\")\ntokenizer.save_pretrained(\"./final_model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:54:17.777139Z","iopub.execute_input":"2025-06-11T09:54:17.777776Z","iopub.status.idle":"2025-06-11T09:54:18.258481Z","shell.execute_reply.started":"2025-06-11T09:54:17.777755Z","shell.execute_reply":"2025-06-11T09:54:18.257930Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('./final_model/tokenizer_config.json',\n './final_model/special_tokens_map.json',\n './final_model/sentencepiece.bpe.model',\n './final_model/added_tokens.json')"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import shutil\n\n# Create a ZIP file from the final_model folder\nshutil.make_archive('/kaggle/working/final_model', 'zip', './final_model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T09:54:37.372525Z","iopub.execute_input":"2025-06-11T09:54:37.372771Z","iopub.status.idle":"2025-06-11T09:54:49.147906Z","shell.execute_reply.started":"2025-06-11T09:54:37.372754Z","shell.execute_reply":"2025-06-11T09:54:49.147348Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/final_model.zip'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"import os\nos.path.exists('/kaggle/working/final_model.zip')  # should return True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T10:01:09.457729Z","iopub.execute_input":"2025-06-11T10:01:09.457999Z","iopub.status.idle":"2025-06-11T10:01:09.462737Z","shell.execute_reply.started":"2025-06-11T10:01:09.457978Z","shell.execute_reply":"2025-06-11T10:01:09.462028Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n# trainer.save_model(\"./final_model\")\n# tokenizer.save_pretrained(\"./final_model\")\n\n# Configure 4-bit quantization\nquant_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n\n# Load model and tokenizer from Kaggle input directory\nmodel_path = \"/kaggle/input/eng-asm/transformers/default/1\"\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n    model_path,\n    torch_dtype=torch.float16,\n    #quantization_config=quant_config,\n    device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n\n# Set target language\ntgt_lang = \"asm_Beng\"\nforced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\nmodel.config.forced_bos_token_id = forced_bos_token_id\nmodel.config.use_cache = True\n\n# Load Manipuri test sentences\ntest_file = \"/kaggle/input/engtasmtest/en-as.txt\"\nwith open(test_file, \"r\", encoding=\"utf-8\") as f:\n    manipuri_sentences = [line.split(\"\\t\")[0].strip() for line in f if line.strip()]\n\nfrom tqdm import tqdm  \n\neng_predictions = []\nfor sentence in tqdm(manipuri_sentences, desc=\"Translating\"):\n    inputs = tokenizer(\n        f\"eng_Latn {sentence}\",\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=256\n    ).to(model.device)\n\n    outputs = model.generate(\n        **inputs,\n        forced_bos_token_id=forced_bos_token_id,\n        max_length=256,\n        num_beams=5\n    )\n    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    eng_predictions.append(decoded)\n\n# Save predictions\nwith open(\"myresult.txt\", \"w\", encoding=\"utf-8\") as f:\n    for pred in eng_predictions:\n        f.write(pred + \"\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T12:05:27.415156Z","iopub.execute_input":"2025-06-11T12:05:27.415445Z","iopub.status.idle":"2025-06-11T12:43:20.435649Z","shell.execute_reply.started":"2025-06-11T12:05:27.415423Z","shell.execute_reply":"2025-06-11T12:43:20.434872Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f08e51f267a4027b4da9a24382c8a93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin.index.json:   0%|          | 0.00/90.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a171bcc937d440aa2b765a979cc4a8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7806e634c63a4cd6add030101b4f5871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00003-of-00003.bin:   0%|          | 0.00/2.10G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3afbdf01bc6446369f8b6da6739a2bdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00002-of-00003.bin:   0%|          | 0.00/8.55G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dfd945721b94f4db871e1bfd794b005"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model-00001-of-00003.bin:   0%|          | 0.00/6.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c371efea38346c097789aaafc0333bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/94.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc392df8344458ba9474d042bbc89a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa6270806fe4030a7a444ed229ac7d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35ffc87bf42d45b1a851e05392cc0f52"}},"metadata":{}},{"name":"stderr","text":"Translating:   0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1667: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\nTranslating: 100%|██████████| 1000/1000 [34:44<00:00,  2.08s/it]\n","output_type":"stream"}],"execution_count":5}]}